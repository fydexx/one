#!/bin/bash

# -------------------------------------------------------------------------- #
# Copyright 2002-2018, OpenNebula Project, OpenNebula Systems                #
#                                                                            #
# Licensed under the Apache License, Version 2.0 (the "License"); you may    #
# not use this file except in compliance with the License. You may obtain    #
# a copy of the License at                                                   #
#                                                                            #
# http://www.apache.org/licenses/LICENSE-2.0                                 #
#                                                                            #
# Unless required by applicable law or agreed to in writing, software        #
# distributed under the License is distributed on an "AS IS" BASIS,          #
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.   #
# See the License for the specific language governing permissions and        #
# limitations under the License.                                             #
#--------------------------------------------------------------------------- #

# cpds host:remote_system_ds/disk.i fe:SOURCE snapid vmid dsid
#   - fe is the front-end hostname
#   - SOURCE is the path of the disk image in the form DS_BASE_PATH/disk
#   - host is the target host to deploy the VM
#   - remote_system_ds is the path for the system datastore in the host
#   - snapid is the snapshot id. "-1" for none
#   - dsid is the target datastore

SRC=$1
DST=$2
SNAP_ID=$3
VMID=$4
DSID=$5

if [ -z "${ONE_LOCATION}" ]; then
    TMCOMMON=/var/lib/one/remotes/tm/tm_common.sh
else
    TMCOMMON=$ONE_LOCATION/var/remotes/tm/tm_common.sh
fi

DRIVER_PATH=$(dirname $0)

. $TMCOMMON
. ${DRIVER_PATH}/../../etc/vmm/kvm/kvmrc

#-------------------------------------------------------------------------------
# Get Image information
#-------------------------------------------------------------------------------

DISK_ID=$(basename ${SRC} | cut -d. -f2)

XPATH="${DRIVER_PATH}/../../datastore/xpath.rb --stdin"

unset i j XPATH_ELEMENTS

while IFS= read -r -d '' element; do
    XPATH_ELEMENTS[i++]="$element"
done < <(onevm show -x $VMID| $XPATH \
                    /VM/DEPLOY_ID \
                    /VM/LCM_STATE \
                    /VM/TEMPLATE/DISK[DISK_ID=$DISK_ID]/TARGET)

DEPLOY_ID="${XPATH_ELEMENTS[j++]}"
LCM_STATE="${XPATH_ELEMENTS[j++]}"
DISK_TARGET="${XPATH_ELEMENTS[j++]}"

#-------------------------------------------------------------------------------
# Set src path
#-------------------------------------------------------------------------------

SRC_PATH=`arg_path $SRC`
SRC_HOST=`arg_host $SRC`
SRC_TEMP_PATH=$(mktemp -u ${SRC_PATH}.XXXXXXXX)

if [ "${SNAP_ID}" != "-1" ]; then
    SRC="${SRC}.snap/${SNAP_ID}"
fi

#-------------------------------------------------------------------------------
# Move the image back to the datastore
#-------------------------------------------------------------------------------
# For current image of the running VMs, don't touch the image directly,
# but export the content via blockcopy. If that's not possible (old QEMU),
# domfsfreeze or suspend the domain before.

if [ "${LCM_STATE}" = '26' ] && [ "${SNAP_ID}" = '-1' ]; then

    # Touch the blockcopy export first
    if ssh_exec_and_log_no_error "$SRC_HOST" "touch ${SRC_TEMP_PATH}" "Error touching ${SRC_TEMP_PATH}"; then
        trap "ssh_exec_and_log_no_error ${SRC_HOST} \"rm ${SRC_TEMP_PATH}\"" EXIT TERM INT HUP

        BLOCKCOPY_CMD="virsh -c ${LIBVIRT_URI} blockcopy ${DEPLOY_ID} ${DISK_TARGET} ${SRC_TEMP_PATH} --wait --finish"
        BLOCKCOPY_ERR_MSG="Error creating blockcopy from domain ${DEPLOY_ID} disk ${DISK_TARGET} at ${SRC_TEMP_PATH}"
        if ssh_exec_and_log_no_error "$SRC_HOST" "$BLOCKCOPY_CMD" "$BLOCKCOPY_ERR_MSG"; then

            # Modify the SRC to point to created blockcopy export
            SRC="${SRC_HOST}:${SRC_TEMP_PATH}"
        fi
    else
        FSFREEZE_CMD="virsh -c ${LIBVIRT_URI} domfsfreeze ${DEPLOY_ID}"
        FSREEZE_ERR_MSG="Error running domfsfreeze on domain ${DEPLOY_ID}"
        if ssh_exec_and_log_no_error "$SRC_HOST" "$FSFREEZE_CMD" "$FSREEZE_ERR_MSG"; then
            trap "virsh -c ${LIBVIRT_URI} domfsthaw ${DEPLOY_ID}" EXIT TERM INT HUP
        else
            SUSPEND_CMD="virsh -c ${LIBVIRT_URI} suspend ${DEPLOY_ID}"
            SUSPEND_ERR_MSG="Error running suspend on domain ${DEPLOY_ID}"
            if ssh_exec_and_log_no_error "$SRC_HOST" "$SUSPEND_CMD" "$SUSPEND_ERR_MSG"; then
                trap "virsh -c ${LIBVIRT_URI} resume ${DEPLOY_ID}" EXIT TERM INT HUP
            fi
        fi
    fi
fi

log "Moving $SRC to datastore as $DST"
exec_and_log "$SCP -r $SRC $DST" "Error copying $SRC to $DST"

exit 0
